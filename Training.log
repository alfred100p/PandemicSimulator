2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 0 -- PandemicGym
2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 1 -- DISCRETE
2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 2 -- 3
2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 3 -- None
2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 4 -- 13
2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 5 -- {'learning_rate': 0.005, 'linear_hidden_units': [20, 10], 'final_layer_activation': ['SOFTMAX', None], 'gradient_clipping_norm': 5.0, 'discount_rate': 0.99, 'epsilon_decay_rate_denominator': 1.0, 'normalise_rewards': True, 'exploration_worker_difference': 2.0, 'clip_rewards': False, 'Actor': {'learning_rate': 0.0001, 'linear_hidden_units': [128], 'final_layer_activation': 'Softmax', 'batch_norm': False, 'tau': 0.005, 'gradient_clipping_norm': 5, 'initialiser': 'Xavier'}, 'Critic': {'learning_rate': 0.001, 'linear_hidden_units': [128], 'final_layer_activation': None, 'batch_norm': False, 'buffer_size': 1000, 'tau': 0.005, 'gradient_clipping_norm': 5, 'initialiser': 'Xavier'}, 'min_steps_before_learning': 1200, 'batch_size': 16, 'mu': 0.0, 'theta': 0.15, 'sigma': 0.25, 'action_noise_std': 0.2, 'action_noise_clipping_range': 0.5, 'update_every_n_steps': 30, 'learning_updates_per_learning_session': 1, 'automatically_tune_entropy_hyperparameter': True, 'entropy_term_weight': None, 'add_extra_noise': False, 'do_evaluation_iterations': True}
2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 6 -- 0
2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 7 -- 30
2022-04-14 14:45:20,774 - agents.Base_Agent - INFO - 8 -- cpu
2022-04-14 14:45:20,951 - agents.Base_Agent - INFO - Reseting game -- New start state [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
2022-04-14 14:47:40,348 - agents.Base_Agent - INFO - Reseting game -- New start state [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
